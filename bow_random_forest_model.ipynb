{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "",
  "signature": "sha256:9f7f46c49fe30947d7c2555ad5cf60b7235c57f1dc5cf5b237010ee89d754ca4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The goal of this notebook is to study the importance of natural language representation in sentiment predicitive models\n",
      "\n",
      "+ We use yelp data set for classifying reviews into positive or negative sentiments\n",
      "+ We use random forest as our classifier\n",
      "+ We use two language representaion for reviews:\n",
      "    + Bag of words\n",
      "    + Word-2-vec\n",
      "\n",
      "Intutively, word-2-vec model takes into account local structure of words in sentences and exploits this locality to trasform words into a numeric space where, sentimentally speaking, closely related words are close to each other. On the other hand, bag of words ignores this inherenet locality.\n",
      "\n",
      "The quantitative results shhow that on the same dataset word-2-vec model acheives better classification accuracy boosting the AUC from 0.9 to 0.93.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#nltk.download('punkt')\n",
      "#nltk.download('stopwords')\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import nltk\n",
      "from bs4 import BeautifulSoup\n",
      "import re\n",
      "import random\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from nltk.corpus import stopwords # Import the stop word list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Transfrom raw yelp data to training and test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "yelp_raw = pd.read_csv(\"/mnt/d/Wash U/personal projects/yelp-dataset/yelp_review.csv\",nrows=100000)\n",
      "print('Example of raw recorded review...')\n",
      "print(yelp_raw.head(1))\n",
      "print('Number of features: {nfeatures}'.format(nfeatures=yelp_raw.shape[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Example of raw recorded review...\n",
        "                review_id                 user_id             business_id  \\\n",
        "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
        "\n",
        "   stars        date                                               text  \\\n",
        "0      5  2016-05-28  Super simple place but amazing nonetheless. It...   \n",
        "\n",
        "   useful  funny  cool  \n",
        "0       0      0     0  \n",
        "Number of features: 9\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Setting label for each review: stars>{0} means a positive review!'.format(2))\n",
      "newcol = (yelp_raw['stars'] > 2)\n",
      "yelp_raw['label'] = newcol;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Setting label for each review: stars>2 means a positive review!\n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.seed(111)\n",
      "yelp_sample = yelp_raw.sample(10000)\n",
      "\n",
      "print('dimension of sampled data: {shape}'.format(shape=yelp_sample.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dimension of sampled data: (10000, 10)\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('generating training and test data...')\n",
      "train=pd.DataFrame(yelp_sample.sample(frac=0.9))\n",
      "test=yelp_sample.drop(train.index)\n",
      "print('done!')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "generating training and test data...\n",
        "done!\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Example of raw review\\n')\n",
      "indices=train['text'].index\n",
      "train['text'][indices[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Example of raw review\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 120,
       "text": [
        "'Best little sandwich spot downtown! This place was awesome, all the menu items have cool names. I had the Baccarat; super mouth watering hot pastrami. My friends had \"the loaded dice\" and \"the poker face\". Just as we were finishing up the owner, Avery, came out and spent some time with us. What a cool low key spot'"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Cleaning raw review data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def review_to_words( raw_review ):\n",
      "    # Function to convert a raw review to a string of words\n",
      "    # The input is a single string (a raw movie review), and \n",
      "    # the output is a single string (a preprocessed movie review)\n",
      "    #\n",
      "    # 1. Remove HTML\n",
      "    review_text = BeautifulSoup(raw_review,\"html5lib\").get_text() \n",
      "    #\n",
      "    # 2. Remove non-letters        \n",
      "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
      "    #\n",
      "    # 3. Convert to lower case, split into individual words\n",
      "    words = letters_only.lower().split()                             \n",
      "    #\n",
      "    # 4. In Python, searching a set is much faster than searching\n",
      "    #   a list, so convert the stop words to a set\n",
      "    stops = set(stopwords.words(\"english\"))                  \n",
      "    # \n",
      "    # 5. Remove stop words\n",
      "    meaningful_words = [w for w in words if not w in stops]   \n",
      "    #\n",
      "    # 6. Join the words back into one string separated by space, \n",
      "    # and return the result.\n",
      "    return( \" \".join( meaningful_words ))   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a simple test\n",
      "\n",
      "clean_review = review_to_words(\"Hesam is not my name\")\n",
      "\n",
      "print('raw text: {r}\\nparsed text: {p}'.format(r=\"Hesam is not my name\",p=clean_review))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "raw text: Hesam is not my name\n",
        "parsed text: hesam name\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the clean training reviews\n",
      "num_reviews = train[\"text\"].size\n",
      "indices=train[\"text\"].index\n",
      "print(\"Cleaning and parsing the training set movie reviews...\\n\")\n",
      "clean_train_reviews = []\n",
      "for i in range( 0, num_reviews):\n",
      "    # If the index is evenly divisible by 1000, print a message\n",
      "    if( (i+1)%1000 == 0 ):\n",
      "        print(\"Review %d of %d\\n\" % ( i+1, num_reviews ))   \n",
      "    \n",
      "    clean_train_reviews.append( review_to_words(train[\"text\"][indices[i]] ))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cleaning and parsing the training set movie reviews...\n",
        "\n",
        "Review 1000 of 9000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Review 2000 of 9000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Review 3000 of 9000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Review 4000 of 9000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Review 5000 of 9000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Review 6000 of 9000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Review 7000 of 9000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Review 8000 of 9000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Review 9000 of 9000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Get clean test reviews\n",
      "\n",
      "# Verify the size of test data\n",
      "print(test.shape)\n",
      "\n",
      "# Create an empty list and append the clean reviews one by one\n",
      "num_reviews = len(test[\"text\"])\n",
      "clean_test_reviews = [] \n",
      "indices=test[\"text\"].index\n",
      "print(\"Cleaning and parsing the test set yelp reviews...\\n\")\n",
      "for i in range(0,num_reviews):\n",
      "    if( (i+1) % 1000 == 0 ):\n",
      "        print(\"Review %d of %d\\n\" %(i+1, num_reviews))\n",
      "    clean_review = review_to_words( test[\"text\"][indices[i]] )\n",
      "    clean_test_reviews.append( clean_review )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 10)\n",
        "Cleaning and parsing the test set yelp reviews...\n",
        "\n",
        "Review 1000 of 1000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Build training features based on bag of words "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Creating the bag of words...\\n\")\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
      "# bag of words tool.  \n",
      "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
      "                             tokenizer = None,    \\\n",
      "                             preprocessor = None, \\\n",
      "                             stop_words = None,   \\\n",
      "                             max_features = 5000) \n",
      "\n",
      "# fit_transform() does two functions: First, it fits the model\n",
      "# and learns the vocabulary; second, it transforms our training data\n",
      "# into feature vectors. The input to fit_transform should be a list of \n",
      "# strings.\n",
      "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
      "\n",
      "# Numpy arrays are easy to work with, so convert the result to an \n",
      "# array\n",
      "train_data_features = train_data_features.toarray()\n",
      "\n",
      "print('\\n Done!')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating the bag of words...\n",
        "\n",
        "\n",
        " Done!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('assign vocabularly to a vocab variable')\n",
      "vocab = vectorizer.get_feature_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "assign vocabularly to a vocab variable\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Training the random forest...\")\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "# Initialize a Random Forest classifier with 200 trees\n",
      "forest = RandomForestClassifier(n_estimators = 200) \n",
      "\n",
      "# Fit the forest to the training set, using the bag of words as \n",
      "# features and the sentiment labels as the response variable\n",
      "#\n",
      "# This may take a few minutes to run\n",
      "forest = forest.fit( train_data_features, train[\"label\"] )\n",
      "print(\"Done!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training the random forest...\n",
        "Done!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = {'value': forest.feature_importances_,'word':vocab}\n",
      "myDf = pd.DataFrame(data=d)\n",
      "print('Get the top {n} mportant features\\n'.format(n=10))\n",
      "inx = (myDf.sort_values('value').tail(10).index.values)\n",
      "for i in inx:\n",
      "    print('{word}'.format(word=vocab[i]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Get the top 10 mportant features\n",
        "\n",
        "money\n",
        "poor\n",
        "said\n",
        "terrible\n",
        "asked\n",
        "told\n",
        "rude\n",
        "great\n",
        "worst\n",
        "horrible\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myDf.sort_values('value').tail(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>value</th>\n",
        "      <th>word</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2813</th>\n",
        "      <td>0.005929</td>\n",
        "      <td>money</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3285</th>\n",
        "      <td>0.006122</td>\n",
        "      <td>poor</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>238</th>\n",
        "      <td>0.006998</td>\n",
        "      <td>asked</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3730</th>\n",
        "      <td>0.007271</td>\n",
        "      <td>said</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4433</th>\n",
        "      <td>0.009330</td>\n",
        "      <td>terrible</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3706</th>\n",
        "      <td>0.009905</td>\n",
        "      <td>rude</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4516</th>\n",
        "      <td>0.010559</td>\n",
        "      <td>told</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1945</th>\n",
        "      <td>0.014222</td>\n",
        "      <td>great</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4947</th>\n",
        "      <td>0.014226</td>\n",
        "      <td>worst</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2129</th>\n",
        "      <td>0.016585</td>\n",
        "      <td>horrible</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "         value      word\n",
        "2813  0.005929     money\n",
        "3285  0.006122      poor\n",
        "238   0.006998     asked\n",
        "3730  0.007271      said\n",
        "4433  0.009330  terrible\n",
        "3706  0.009905      rude\n",
        "4516  0.010559      told\n",
        "1945  0.014222     great\n",
        "4947  0.014226     worst\n",
        "2129  0.016585  horrible"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Get a bag of words for the test set, and convert to a numpy array\n",
      "test_data_features = vectorizer.transform(clean_test_reviews)\n",
      "test_data_features = test_data_features.toarray()\n",
      "\n",
      "# Use the random forest to make sentiment label predictions\n",
      "result = forest.predict(test_data_features)\n",
      "# Copy the results to a pandas dataframe with an \"id\" column and\n",
      "# a \"sentiment\" column\n",
      "output = pd.DataFrame( data={\"id\":test[\"review_id\"], \"text\":test[\"text\"], \"stars\":test[\"stars\"], \"predicted sentiment\":result} );\n",
      "\n",
      "# Use pandas to write the comma-separated output file\n",
      "output.to_csv( \"./data/Bag_of_Words_model.csv\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evaluate the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "fpr, tpr, _ = roc_curve(test['label'], forest.predict_proba(test_data_features)[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "roc_auc = auc(fpr, tpr)\n",
      "print('ROC AUC: %0.2f' % roc_auc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ROC AUC: 0.90\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot of a ROC curve for a specific class\n",
      "plt.figure()\n",
      "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('ROC Curve')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Beyond bag of words: exploiting structure in natural language "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import a pre-trained word-2-vec model\n",
      "import pickle\n",
      "     \n",
      "with open ('outfile_model_p2', 'rb') as fp:\n",
      "    model = pickle.load(fp)\n",
      "\n",
      "print(type(model))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# word-2-vec first 5 diemsion for good and great\n",
      "print('good: {g}\\ngreat: {gr}'.format(g=model['good'][1:5],gr=model['great'][1:5]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "good: [-0.02461446  0.10025943  0.04140808 -0.03861581]\n",
        "great: [ 0.0240189   0.07179239  0.03036534 -0.03032569]\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Represent a review by avergaing its words in the space of wor-2-vec"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "R2Vec = []\n",
      "index = []\n",
      "\n",
      "# check if for each training review all the words are encoded in the word-2-vec space\n",
      "for i in range(0,len(clean_train_reviews)):\n",
      "    try:\n",
      "        W2Vec = model[nltk.word_tokenize(clean_train_reviews[i])]\n",
      "        R2Vec.append(np.mean(W2Vec, axis=0))\n",
      "        index.append(i)\n",
      "    except Exception:\n",
      "        pass\n",
      "\n",
      "R2Vec = np.array(R2Vec)\n",
      "\n",
      "\n",
      "R2Vec_test=[]\n",
      "index_test=[]\n",
      "# check if for each test review all the words are encoded in the word-2-vec space\n",
      "for i in range(0,len(clean_test_reviews)):\n",
      "    try:\n",
      "        W2Vec = model[nltk.word_tokenize(clean_test_reviews[i])]\n",
      "        R2Vec_test.append(np.mean(W2Vec, axis=0))\n",
      "        index_test.append(i)\n",
      "    except Exception:\n",
      "        pass\n",
      "\n",
      "R2Vec_test = np.array(R2Vec_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('number of valid reviews: {n}\\n'.format(n=R2Vec.shape[0]))\n",
      "trainVec = train.iloc[index]\n",
      "print('Distribution of reviews')\n",
      "print(trainVec.label.value_counts())\n",
      "\n",
      "print('number of valid test reviews: {n}'.format(n=R2Vec_test.shape[0]))\n",
      "testVec = test.iloc[index_test]\n",
      "print('\\nDistribution of test reviews')\n",
      "print(testVec.label.value_counts())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "number of valid reviews: 5482\n",
        "\n",
        "Distribution of reviews\n",
        "True     4375\n",
        "False    1107\n",
        "Name: label, dtype: int64\n",
        "number of valid test reviews: 612\n",
        "\n",
        "Distribution of test reviews\n",
        "True     504\n",
        "False    108\n",
        "Name: label, dtype: int64\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "# Instantiate model with 200 decision trees\n",
      "rf = RandomForestClassifier(n_estimators = 200, random_state = 42, n_jobs = -1)\n",
      "# Train the model on training data\n",
      "rf.fit(R2Vec, trainVec['label'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 148,
       "text": [
        "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
        "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Test the predicitve model based on random forest and word-2vec average"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = ['Awesome! I liked this place!', \n",
      "        'Horrible food! Disrespectful staff and very noisy environment', \n",
      "        'very bad food! My dish was very smelly and horrible',\n",
      "        'The food was acceptable but the service was aweful. I liked the decoration of the restaurant.',\n",
      "        'I had a very good experience. The food was delicious and the service was fast.',\n",
      "        'I ordered a salad. there was an insect in the plate. not a good night.',\n",
      "        'it was an OK experience. I do recommend this place. I will come back with friends again.',\n",
      "        'very good! I was impressed with the food. Friendly staff!'];\n",
      "W2Vec_test=np.zeros((len(text),300))\n",
      "for i in  range(len(text)):\n",
      "     W2Vec_test[i,:]=np.mean(model[nltk.word_tokenize(review_to_words(text[i]))], axis=0);\n",
      "print(W2Vec_test.shape)\n",
      "\n",
      "\n",
      "map(lambda x:x>.5,rf.predict(W2Vec_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(8, 300)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 129,
       "text": [
        "[True, False, False, True, True, True, True, True]"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "fpr, tpr, _ = roc_curve(testVec['label'], rf.predict_proba(R2Vec_test)[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "roc_auc = auc(fpr, tpr)\n",
      "print('ROC AUC: %0.2f' % roc_auc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ROC AUC: 0.93\n"
       ]
      }
     ],
     "prompt_number": 147
    }
   ],
   "metadata": {}
  }
 ]
}